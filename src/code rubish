



bool ILPAlgorithmBasicFlows_glpk(Graph *p_graph) {
	char s[1000];
	string strc;

	glp_prob *lp;
	lp = glp_create_prob();
	glp_set_prob_name(lp, "sample");
	glp_set_obj_dir(lp, GLP_MIN);
	int rownum = (2 * p_graph->nodeNum) + p_graph->edgeNum
			+ (3 * p_graph->srlgGroupsNum);
	int colnum = (2 * p_graph->edgeNum + 2 * p_graph->srlgGroupsNum);

	int index = 0;
	//AX1=u

	glp_add_cols(lp, colnum);
	//APedge
	strc = "APedge";
	for (int i = 1; i <= p_graph->edgeNum; i++) {
		sprintf(s, "%d", i);
		glp_set_col_name(lp, i + index, (strc + s).c_str());
		glp_set_col_kind(lp, i + index, GLP_IV);
		glp_set_col_bnds(lp, i, GLP_DB, 0.0, 1.0);
//		glp_set_col_stat(lp, i+ index,GLP_BS);
		glp_set_obj_coef(lp, i, p_graph->edges.at(i - 1).cost);

	}
	//BPedge
	index += p_graph->edgeNum;
	strc = "BPedge";
	for (int i = 1; i <= p_graph->edgeNum; i++) {
		sprintf(s, "%d", i);
		glp_set_col_name(lp, i + index, (strc + s).c_str());
		glp_set_col_kind(lp, i + index, GLP_IV);
		glp_set_col_bnds(lp, i + index, GLP_DB, 0.0, 1.0);
		glp_set_obj_coef(lp, i + index, 0.0);
//		glp_set_col_stat(lp, i+ index,GLP_BS);

	}

	//APsrlg
	index += p_graph->edgeNum;
	strc = "APsrlg";
	for (int i = 1; i <= p_graph->srlgGroupsNum; i++) {
		sprintf(s, "%d", i);
		glp_set_col_name(lp, i + index, (strc + s).c_str());
		glp_set_col_kind(lp, i + index, GLP_IV);
		glp_set_col_bnds(lp, i + index, GLP_DB, 0.0, 1.0);
		glp_set_obj_coef(lp, i + index, 0.0);
//		glp_set_col_stat(lp, i+ index,GLP_BS);

	}
	//BPsrlg
	index += p_graph->srlgGroupsNum;
	strc = "BPsrlg";
	for (int i = 1; i <= p_graph->srlgGroupsNum; i++) {
		sprintf(s, "%d", i);
		glp_set_col_name(lp, i + index, (strc + s).c_str());
		glp_set_col_kind(lp, i + index, GLP_IV);
		glp_set_col_bnds(lp, i + index, GLP_DB, 0.0, 1.0);
		glp_set_obj_coef(lp, i + index, 0.0);
//		glp_set_col_stat(lp, i+ index,GLP_NS);

	}



	index=0;
	glp_add_rows(lp, rownum);
	strc = "APinoutdegrezero";
	for (int i = 1; i <= p_graph->nodeNum; i++) {
		sprintf(s, "%d", i);

		glp_set_row_name(lp, i, (strc + s).c_str());
		if ((i - 1) == p_graph->source)
			glp_set_row_bnds(lp, i, GLP_FX, 1.0, 1.0);
		if ((i - 1) == p_graph->destination)
			glp_set_row_bnds(lp, i, GLP_FX, -1.0, -1.0);
		if (((i - 1) != p_graph->source) && ((i - 1) != p_graph->destination))
			glp_set_row_bnds(lp, i, GLP_FX, 0.0, 0.0);

	}

	//AX2=u
	index += p_graph->nodeNum;
	strc = "BPinoutdegrezero";
	for (int i = 1; i <= p_graph->nodeNum; i++) {
		sprintf(s, "%d", i);
		glp_set_row_name(lp, i + index, (strc + s).c_str());
		if ((i - 1) == p_graph->source)
			glp_set_row_bnds(lp, i + index, GLP_FX, 1.0, 1.0);
		if ((i - 1) == p_graph->destination)
			glp_set_row_bnds(lp, i + index, GLP_FX, -1.0, -1.0);
		if (((i - 1) != p_graph->source) && ((i - 1) != p_graph->destination))
			glp_set_row_bnds(lp, i + index, GLP_FX, 0.0, 0.0);
	}

	//0<=X1+X2<=1
	index += p_graph->nodeNum;
	strc = "APnotcrossBP";
	for (int i = 1; i <= p_graph->edgeNum; i++) {
		sprintf(s, "%d", i);
		glp_set_row_name(lp, i + index, (strc + s).c_str());
		glp_set_row_bnds(lp, i + index, GLP_DB, 0.0, 1.0);
	}

	//HX1-|E0|Z1<=0
	index += p_graph->edgeNum;
	strc = "APsrlg";
	for (int i = 1; i <= p_graph->srlgGroupsNum; i++) {
		sprintf(s, "%d", i);
		glp_set_row_name(lp, i + index, (strc + s).c_str());
		glp_set_row_bnds(lp, (i + index), GLP_DB, 0.0, 1.0);

	}
	//HX2-|E0|Z2<=0
	index += p_graph->srlgGroupsNum;
	strc = "BPsrlg";
	for (int i = 1; i <= p_graph->srlgGroupsNum; i++) {
		sprintf(s, "%d", i);
		glp_set_row_name(lp, i + index, (strc + s).c_str());
		glp_set_row_bnds(lp, (i + index), GLP_DB, 0.0, 1.0);

	}

	//0<=Z1+Z2<=1
	index += p_graph->srlgGroupsNum;
	strc = "APnotcrossBP";
	for (int i = 1; i <= p_graph->srlgGroupsNum; i++) {
		sprintf(s, "%d", i);
		glp_set_row_name(lp, i + index, (strc + s).c_str());
		glp_set_row_bnds(lp, (i + index), GLP_DB, 0.0, 1.0);
	}


	int *ia, *ja;
	double *ar;
	ia = (int*) malloc(((rownum * colnum) + 2) * sizeof(int));
	ja = (int*) malloc(((rownum * colnum) + 2) * sizeof(int));
	ar = (double*) malloc(((rownum * colnum) + 2) * sizeof(double));
	int jlimit1 = p_graph->edgeNum;
	int jlimit2 = 2 * p_graph->edgeNum;
	int jlimit3 = 2 * p_graph->edgeNum + p_graph->srlgGroupsNum;

	index = 1;
	int indexrow = 0;
	//AX1=u
	for (int i = 0; i < p_graph->nodeNum; i++) {
		for (int j = 0; j < colnum; j++) {
			ia[index] = i + 1;
			ja[index] = j + 1;
			ar[index] = 0;
			if (j < jlimit1) {
				if (i == p_graph->edges.at(j).from) {
					ar[index] = 1;
				}
				if (i == p_graph->edges.at(j).to) {
					ar[index] = -1;
				}
			}
			index++;
		}
	}
	//AX2=u
	indexrow += p_graph->nodeNum;
	for (int i = 0; i < p_graph->nodeNum; i++) {
		for (int j = 0; j < colnum; j++) {
			ia[index] = i + 1 + indexrow;
			ja[index] = j + 1;
			ar[index] = 0;
			if ((j < jlimit2) && (j >= jlimit1)) {
				if (i == p_graph->edges.at(j - jlimit1).from) {
					ar[index] = 1;
				}
				if (i == p_graph->edges.at(j - jlimit1).to) {
					ar[index] = -1;
				}
			}
			index++;
		}
	}
	//0<=X1+X2<=1
	indexrow += p_graph->nodeNum;
	for (int i = 0; i < p_graph->edgeNum; i++) {
		for (int j = 0; j < colnum; j++) {
			ia[index] = i + 1 + indexrow;
			ja[index] = j + 1;
			ar[index] = 0;
			if (j < jlimit1) {
				if (i == j) {
					ar[index] = 1;
				}
			}
			if ((j < jlimit2) && (j >= jlimit1)) {
				if (i == (j - jlimit1)) {
					ar[index] = 1;
				}
			}
			index++;
		}
	}

	//HX1-|E0|Z1<=0
	indexrow += p_graph->edgeNum;
	int E0 = p_graph->edgeNum;
	for (int i = 0; i < p_graph->srlgGroupsNum; i++) {
		for (int j = 0; j < colnum; j++) {
			ia[index] = i + 1 + indexrow;
			ja[index] = j + 1;
			ar[index] = 0;
			if (j < jlimit1) {
				if (i == p_graph->edges.at(j).ithsrlg) {
					ar[index] = -1;
				}
			}
			if ((j < jlimit3) && (j >= jlimit2)) {
				if (i == (j - jlimit2)) {
					ar[index] = 1.0
							* (p_graph->srlgGroups.at(i).srlgMember.size());
				}
			}
			index++;
		}
	}
	//HX2-|E0|Z2<=0
	indexrow += p_graph->srlgGroupsNum;
	for (int i = 0; i < p_graph->srlgGroupsNum; i++) {
		for (int j = 0; j < colnum; j++) {
			ia[index] = i + 1 + indexrow;
			ja[index] = j + 1;
			ar[index] = 0;
			if ((j >= jlimit1) && (j < jlimit2)) {
				if (i == p_graph->edges.at(j - jlimit1).ithsrlg)
					ar[index] = -1.0;

			}
			if ((j >= jlimit3)) {
				if (i == (j - jlimit3)) {
					ar[index] = 1.0
						* (p_graph->srlgGroups.at(i).srlgMember.size());
				}
			}
			index++;
		}
	}
	//0<=Z1+Z2<=1
	indexrow += p_graph->srlgGroupsNum;
	for (int i = 0; i < p_graph->srlgGroupsNum; i++) {
		for (int j = 0; j < colnum; j++) {
			ia[index] = i + 1 + indexrow;
			ja[index] = j + 1;
			ar[index] = 0;
			if ((j < jlimit3) && (j >= jlimit2)) {
				if ((j - jlimit2) == i) {
					ar[index] = 1;
				}
			}
			if ((j >= jlimit3)) {
				if ((j - jlimit3) == i) {
					ar[index] = 1;
				}
			}
			index++;

		}
	}

	glp_load_matrix(lp, (rownum * colnum), ia, ja, ar);
	glp_simplex(lp, NULL);
//	glp_interior(lp,NULL);

	if (!(GLP_OPT == glp_get_status(lp))) {
		return false;
	}
	cout << "ILP value:" << glp_get_obj_val(lp) << endl;
	cout << "glp get num rows" << glp_get_num_rows(lp) << endl;
	cout << "glp_get_num_cols" << glp_get_num_cols(lp) << endl;
	cout << " glp_get_num_nz" << glp_get_num_nz(lp) << endl;
	for (int i = 1; i <= colnum; i++) {
		if (glp_get_col_prim(lp, i)) {
			int id = i - 1;
			cout << glp_get_col_name(lp, i) << ":  " << glp_get_col_prim(lp, i);
//			cout << "  row_type :" << glp_get_col_type(lp, i);
			if (i <= jlimit2) {
				if (i > jlimit1)
					id -= jlimit1;
				cout << "   from "
						<< p_graph->node_index[p_graph->edges.at(id).from]
						<< "  to: "
						<< p_graph->node_index[p_graph->edges.at(id).to];
			}

			cout << endl;

		}
	}

	glp_delete_prob(lp);
	free(ia);
	free(ja);
	free(ar);
	return true;

}


/*
 * franz_nlp.hpp
 *
 *  Created on: Jul 26, 2016
 *      Author: franz
 */

#ifndef SINGLEMUSTNODEPATH_NLP_HPP_
#define SINGLEMUSTNODEPATH_NLP_HPP_
#include "../head.h"
#include "IpTNLP.hpp"

using namespace Ipopt;

/*
 * problem
 *
 * min sum ei*ci (i=1,2...edgenum)
 * s.t.
 * 		1)sum ei(ei=1 ei is vi's from,otherwise -1)=0,1
 * (vj is source),-1(vjis destination)
 * all from or to of ei belong vj(j=1,2..,nodenum)
 * 		2)sum ei<=2,(vj is source),-1(vjis destination)
 * all from or to of ei belong vj(j=1,2..,nodenum)
 *      3)
 */
class franz_NLP: public TNLP {
public:
	Graph *p_graph;
	Request *p_request;
	/** default constructor */
	franz_NLP(Graph *p_graph, Request *p_request);

	/** default destructor */
	virtual ~franz_NLP();

	/**@name Overloaded from TNLP */
	//@{
	/** Method to return some info about the nlp */
	virtual bool get_nlp_info(Index& n, Index& m, Index& nnz_jac_g,
			Index& nnz_h_lag, IndexStyleEnum& index_style);

	/** Method to return the bounds for my problem */
	virtual bool get_bounds_info(Index n, Number* x_l, Number* x_u, Index m,
			Number* g_l, Number* g_u);

	/** Method to return the starting point for the algorithm */
	virtual bool get_starting_point(Index n, bool init_x, Number* x,
			bool init_z, Number* z_L, Number* z_U, Index m, bool init_lambda,
			Number* lambda);

	/** Method to return the objective value */
	virtual bool eval_f(Index n, const Number* x, bool new_x,
			Number& obj_value);

	/** Method to return the gradient of the objective */
	virtual bool eval_grad_f(Index n, const Number* x, bool new_x,
			Number* grad_f);

	/** Method to return the constraint residuals */
	virtual bool eval_g(Index n, const Number* x, bool new_x, Index m,
			Number* g);

	/** Method to return:
	 *   1) The structure of the jacobian (if "values" is NULL)
	 *   2) The values of the jacobian (if "values" is not NULL)
	 */
	virtual bool eval_jac_g(Index n, const Number* x, bool new_x, Index m,
			Index nele_jac, Index* iRow, Index *jCol, Number* values);

	/** Method to return:
	 *   1) The structure of the hessian of the lagrangian (if "values" is NULL)
	 *   2) The values of the hessian of the lagrangian (if "values" is not NULL)
	 */
	virtual bool eval_h(Index n, const Number* x, bool new_x, Number obj_factor,
			Index m, const Number* lambda, bool new_lambda, Index nele_hess,
			Index* iRow, Index* jCol, Number* values);

	//@}

	/** @name Solution Methods */
	//@{
	/** This method is called when the algorithm is complete so the TNLP can store/write the solution */
	virtual void finalize_solution(SolverReturn status, Index n,
			const Number* x, const Number* z_L, const Number* z_U, Index m,
			const Number* g, const Number* lambda, Number obj_value,
			const IpoptData* ip_data, IpoptCalculatedQuantities* ip_cq);
	//@}

private:
	/**@name Methods to block default compiler methods.
	 * The compiler automatically generates the following three methods.
	 *  Since the default compiler implementation is generally not what
	 *  you want (for all but the most simple classes), we usually
	 *  put the declarations of these methods in the private section
	 *  and never implement them. This prevents the compiler from
	 *  implementing an incorrect "default" behavior without us
	 *  knowing. (See Scott Meyers book, "Effective C++")
	 *
	 */
	//@{
	//  HS071_NLP();
	franz_NLP(const franz_NLP&);
	franz_NLP& operator=(const franz_NLP&);
	//@}
};

#endif /* SINGLEMUSTNODEPATH_NLP_HPP_ */

/*
 * franz_nlp.cpp
 *
 *  Created on: Jul 26, 2016
 *      Author: franz
 */

#include "../franz/singlemustnodepath_nlp.hpp"

#include <cassert>
#include <iostream>

using namespace Ipopt;

// constructor
franz_NLP::franz_NLP(Graph *p_graph, Request *p_request) {
	this->p_graph = p_graph;
	this->p_request = p_request;
}

//destructor
franz_NLP::~franz_NLP() {
}

// returns the size of the problem
bool franz_NLP::get_nlp_info(Index& n, Index& m, Index& nnz_jac_g,
		Index& nnz_h_lag, IndexStyleEnum& index_style) {
	// The problem described in franz_NLP.hpp has edgenum variables, x[0] through x[edgenum]
	n = this->p_graph->edgeNum;

	// one equality constraint and one inequality constraint
	m = 2 * this->p_graph->nodeNum;
	int sum = 0;
	// in this example the jacobian is dense and contains sum nonzeros
	for (Index i = 0; i < (m / 2); i++) {
		for (Index j = 0; j < n; j++) {
			if ((i == p_graph->edges.at(j).from)
					|| (i == p_graph->edges.at(j).to))
				sum += 2;
		}
	}
	nnz_jac_g = sum;

	// the hessian is also dense and has 0 total nonzeros, but we
	// only need the lower left corner (since it is symmetric)
	nnz_h_lag = 0;

	// use the C style indexing (0-based)
	index_style = TNLP::C_STYLE;

	return true;
}

// returns the variable bounds
bool franz_NLP::get_bounds_info(Index n, Number* x_l, Number* x_u, Index m,
		Number* g_l, Number* g_u) {
	// here, the n and m we gave IPOPT in get_nlp_info are passed back to us.
	// If desired, we could assert to make sure they are what we think they are.
	assert(n == this->p_graph->edgeNum);
	assert(m == (2 * this->p_graph->nodeNum));

	// the variables have lower bounds of 0
	// the variables have upper bounds of 1
	for (Index i = 0; i < n; i++) {
		x_l[i] = 0.0;
		x_u[i] = 1.0;

		if (!p_request->APMustPassEdges.at(i)) {
			x_l[i] = 1.0;
			x_u[i] = 1.0;

		}
		if (!p_request->APMustNotPassEdges.at(i)) {
			x_l[i] = 0.0;
			x_u[i] = 0.0;

		}
	}

	// Ipopt interprets any number greater than nlp_upper_bound_inf as
	// infinity. The default value of nlp_upper_bound_inf and nlp_lower_bound_inf
	// is 1e19 and can be changed through ipopt options.
	for (Index i = 0; i < m; i++) {
		if (i < (m / 2)) {
			g_l[i] = g_u[i] = 0.0;
			if (i == p_graph->source){

				g_l[i] = g_u[i] = 1.0;
			}
			if (i == p_graph->destination){
				g_l[i] = g_u[i] = -1.0;
			}
		} else {
			g_l[i] = 0.0;
			g_u[i] = 2.0;
		}

	}
	return true;
}

// returns the initial point for the problem
bool franz_NLP::get_starting_point(Index n, bool init_x, Number* x, bool init_z,
		Number* z_L, Number* z_U, Index m, bool init_lambda, Number* lambda) {
	// Here, we assume we only have starting values for x, if you code
	// your own NLP, you can provide starting values for the dual variables
	// if you wish
	assert(init_x == true);  //true
	assert(init_z == false);
	assert(init_lambda == false);

	// initialize to the given starting point
	for (int i = 0; i < p_graph->edgeNum; i++) {
		x[i] = 0.0;
	}
	x[0] = x[3] = x[5] = x[9] = x[10] = x[11] = x[14] = x[16] = x[19] = x[20] =
			x[21] = 1.0;
//  x[0] = 1.0;
//  x[1] = 5.0;
//  x[2] = 5.0;
//  x[3] = 1.0;

	return true;
}

// returns the value of the objective function
bool franz_NLP::eval_f(Index n, const Number* x, bool new_x,
		Number& obj_value) {
	assert(n == this->p_graph->edgeNum);
	obj_value=0;
	for (Index i = 0; i < n; i++) {
//		std::cout<<this->p_graph->edges.at(i).cost<<"FFFFFFFFF\nFFFFFFF\n"<<endl;
		if(this->p_graph->edges.at(i).cost!=0)
		obj_value += (this->p_graph->edges.at(i).cost * x[i]);
	}

	return true;
}

// return the gradient of the objective function grad_{x} f(x)
bool franz_NLP::eval_grad_f(Index n, const Number* x, bool new_x,
		Number* grad_f) {
	assert(n == this->p_graph->edgeNum);
	for (Index i = 0; i < n; i++) {
		grad_f[i] = this->p_graph->edges.at(i).cost;
	}
	return true;
}

// return the value of the constraints: g(x)
bool franz_NLP::eval_g(Index n, const Number* x, bool new_x, Index m,
		Number* g) {
	assert(n == this->p_graph->edgeNum);
	assert(m == (2 * this->p_graph->nodeNum));

	int bi = m / 2;
	for (Index i = 0; i < bi; i++) {
		//g[i] = 0;
		for (Index j = 0; j < n; j++) {
			if (i == p_graph->edges.at(j).from)
				g[i] += x[j];
			if (i == p_graph->edges.at(j).to)
				g[i] += (-1 * x[j]);

		}
	}
	for (Index i = 0; i < bi; i++) {
		//g[i + bi] = 0;
		for (Index j = 0; j < n; j++) {
			if ((i == p_graph->edges.at(j).from)
					|| (i == p_graph->edges.at(j).to))
				g[i + bi] += x[j];
		}
	}
	return true;
}

// return the structure or values of the jacobian
bool franz_NLP::eval_jac_g(Index n, const Number* x, bool new_x, Index m,
		Index nele_jac, Index* iRow, Index *jCol, Number* values) {
	if (values == NULL) {
		// return the structure of the jacobian

		// this particular jacobian is dense
		Index s = 0;
		int bi = m / 2;
		for (Index i = 0; i < m; i++) {
			for (Index j = 0; j < n; j++) {
				if (i < bi) {
					if ((i == p_graph->edges.at(j).from)
							|| (i == p_graph->edges.at(j).to)) {
						iRow[s] = i+1;
						iRow[s] = j+1;
						s++;
					}
				} else {
					if (((i - bi) == p_graph->edges.at(j).from)
							|| ((i - bi) == p_graph->edges.at(j).to)) {
						iRow[s] = i+1;
						iRow[s] = j+1;
						s++;
					}
				}
			}
		}
	} else {
		// return the values of the jacobian of the constraints
		Index s = 0;
		for (Index i = 0; i < (m / 2); i++) {
			for (Index j = 0; j < n; j++) {
				if ((i == p_graph->edges.at(j).from)) {
					values[s] = 1.0;
					s++;
				}
				if (i == p_graph->edges.at(j).to) {
					values[s] = -1.0;
					s++;
				}
			}
		}
		for (Index i = 0; i < (m / 2); i++) {
			for (Index j = 0; j < n; j++) {
				if ((i == p_graph->edges.at(j).from)
						|| (i == p_graph->edges.at(j).to)) {
					values[s] = 1.0;
					s++;
				}
			}
		}
	}

	return true;
}

//return the structure or values of the hessian
bool franz_NLP::eval_h(Index n, const Number* x, bool new_x, Number obj_factor,
		Index m, const Number* lambda, bool new_lambda, Index nele_hess,
		Index* iRow, Index* jCol, Number* values) {
	if (values == NULL) {
		// return the structure. This is a symmetric matrix, fill the lower left
		// triangle only.

		// the hessian for this problem is actually dense
		Index idx = 0;
//		for (Index row = 0; row < n; row++) {
//			for (Index col = 0; col <= row; col++) {
//				iRow[idx] = row;
//				jCol[idx] = col;
//				idx++;
//			}
//		}
		assert(idx == nele_hess);
	} else {
		// return the values. This is a symmetric matrix, fill the lower left
		// triangle only

		// fill the objective portion
//		Index idx = 0;
//		for (Index row = 0; row < n; row++) {
//			for (Index col = 0; col <= row; col++) {
//				values[idx] = 0.;
//			}
//		}

	}

	return true;
}

void franz_NLP::finalize_solution(SolverReturn status, Index n, const Number* x,
		const Number* z_L, const Number* z_U, Index m, const Number* g,
		const Number* lambda, Number obj_value, const IpoptData* ip_data,
		IpoptCalculatedQuantities* ip_cq) {
// here is where we would store the solution to variables, or write to a file, etc
// so we could use the solution.

// For this example, we write the solution to the console
	std::cout << std::endl << std::endl << "Solution of the primal variables, x"
			<< std::endl;
	for (Index i = 0; i < n; i++) {
		std::cout << "x[" << i << "] = " << x[i] << std::endl;
		p_request->BPMustNotPassEdges4AP[i] = false;
	}

	std::cout << std::endl << std::endl
			<< "Solution of the bound multipliers, z_L and z_U" << std::endl;
	for (Index i = 0; i < n; i++) {
		std::cout << "z_L[" << i << "] = " << z_L[i] << std::endl;
	}
	for (Index i = 0; i < n; i++) {
		std::cout << "z_U[" << i << "] = " << z_U[i] << std::endl;
	}

	std::cout << std::endl << std::endl << "Objective value" << std::endl;
	std::cout << "f(x*) = " << obj_value << std::endl;

	std::cout << std::endl << "Final value of the constraints:" << std::endl;
	for (Index i = 0; i < m; i++) {
		std::cout << "g(" << i << ") = " << g[i] << std::endl;
	}
}



int findAP_ILP_ipopt(Graph *p_graph, Request *p_request) {

	// Create a new instance of your nlp
	//  (use a SmartPtr, not raw)
//	SmartPtr<TNLP> mynlp = new franz_NLP(p_graph, p_request);
	SmartPtr<TNLP> mynlp = new franz_NLP(p_graph, p_request);

	// Create a new instance of IpoptApplication
	//  (use a SmartPtr, not raw)
	// We are using the factory, since this allows us to compile this
	// example with an Ipopt Windows DLL
	SmartPtr<IpoptApplication> app = IpoptApplicationFactory();
	app->RethrowNonIpoptException(true);

	// Change some options
	// Note: The following choices are only examples, they might not be
	//       suitable for your optimization problem.
	app->Options()->SetNumericValue("tol", 1e-7);
//	app->Options()->SetNumericValue("max_iter",3);
//	app->Options()->SetIntegerValue("tol");
//	app->Options()->SetStringValue("mu_strategy", "adaptive");
//	app->Options()->SetStringValue("output_file", "ipopt.out");

	// The following overwrites the default name (ipopt.opt) of the
	// options file
	// app->Options()->SetStringValue("option_file_name", "hs071.opt");

	// Initialize the IpoptApplication and process the options
	ApplicationReturnStatus status;
	status = app->Initialize();
	if (status != Solve_Succeeded) {
		std::cout << std::endl << std::endl
				<< "*** Error during initialization!" << std::endl;
		return (int) status;
	}

	// Ask Ipopt to solve the problem
	status = app->OptimizeTNLP(mynlp);;//app->OptimizeTNLP(mynlp);

	if (status == Solve_Succeeded) {
		std::cout << std::endl << std::endl << "*** The problem solved!"
				<< std::endl;
	} else {
		std::cout << std::endl << std::endl << "*** The problem FAILED!"
				<< std::endl;
	}

	// As the SmartPtrs go out of scope, the reference count
	// will be decremented and the objects will automatically
	// be deleted.

	return (int) status;

}


bool ILPAlgorithmBasicFlows_LocalSolver(Graph *p_graph) {

	try {

		/* Declares the optimization model. */
		LocalSolver localsolver;
		LSModel model = localsolver.getModel();

		// 0-1 decisions
		int twocolnum = 2 * p_graph->edgeNum;
		int onecolnum = p_graph->edgeNum;
//		LSExpression *x = new LSExpression(2 * p_graph->edgeNum);
		vector<LSExpression> x; //=new vector<LSExpression>(2 * p_graph->edgeNum);
		x.resize(2 * p_graph->edgeNum);
//        x=(LSExpression *)malloc(2*p_graph->edgeNum*(sizeof(LSExpression)));
		for (int i = 0; i < twocolnum; i++)
			x[i] = model.boolVar();

		// knapsackWeight <- 10*x0 + 60*x1 + 30*x2 + 40*x3 + 30*x4 + 20*x5 + 20*x6 + 2*x7;

		for (int i = 0; i < p_graph->nodeNum; i++) {
			LSExpression knapsackWeight = model.sum();
			lsint knapsackBound;
			knapsackBound = 0;
			if (i == p_graph->source)
				knapsackBound = 1;
			if (i == p_graph->destination)
				knapsackBound = -1;
			for (int j = 0; j < onecolnum; j++) {
				if (i == p_graph->edges.at(j).from)
					knapsackWeight += x[j];
				if (i == p_graph->edges.at(j).to)
					knapsackWeight += (-1 * x[j]);
			}
			model.constraint(knapsackWeight <= knapsackBound);
		}

		for (int i = 0; i < p_graph->nodeNum; i++) {
			LSExpression knapsackWeight = model.sum();
			lsint knapsackBound;
			knapsackBound = 0;
			if (i == p_graph->source)
				knapsackBound = 1;
			if (i == p_graph->destination)
				knapsackBound = -1;
			for (int j = onecolnum; j < twocolnum; j++) {
				if (i == p_graph->edges.at(j - onecolnum).from)
					knapsackWeight += x[j];
				if (i == p_graph->edges.at(j - onecolnum).to)
					knapsackWeight += (-1 * x[j]);
			}
			model.constraint(knapsackWeight <= knapsackBound);
		}

		for (int i = 0; i < onecolnum; i++) {
			LSExpression knapsackWeight = model.sum();
			lsint knapsackBound;
			knapsackBound = 1;

			knapsackWeight += x[i];
			knapsackWeight += x[i + onecolnum];

			model.constraint(knapsackWeight <= knapsackBound);
		}

		for (unsigned int i = 0; i < p_graph->srlgGroupsNum; i++) {
			unsigned srlglen = p_graph->srlgGroups.at(i).srlgMember.size();
			for (unsigned j = 0; j < srlglen; j++) {
				for (unsigned k = 0; k < srlglen; k++) {
					LSExpression knapsackWeight = model.sum();
					lsint knapsackBound;
					knapsackBound = 1;
					knapsackWeight += x[p_graph->srlgGroups.at(i).srlgMember.at(
							j)];
					knapsackWeight += x[p_graph->srlgGroups.at(i).srlgMember.at(
							k)];
					model.constraint(knapsackWeight <= knapsackBound);
				}
			}
		}

		LSExpression obj = model.sum();
		for (int i = 0; i < onecolnum; i++) {
//			if (i < p_graph->edgeNum)
			obj += p_graph->edges.at(i).cost * x[i];
//			else
//				obj += p_graph->edges.at(i - p_graph->edgeNum).cost * x[i];
		}

		// minimize obj;
		model.minimize(obj);

		// close model, then solve
		model.close();

		/* Parameterizes the solver. */
		LSPhase phase = localsolver.createPhase();
		LSSolution solution = localsolver.getSolution();
		phase.setTimeLimit(LimitedTime);
		phase.setEnabled(true);
//		localsolver.LSSolution();
//		phase.setOptimizedObjective(SS_Optimal);

		localsolver.solve();

		vector<bool> apvis = vector<bool>(p_graph->edgeNum, false);
		for (int i = 0; i < onecolnum; i++) {
			if (x[i].getValue())
				apvis[i] = true;

		}

		vector<bool> bpvis = vector<bool>(p_graph->edgeNum, false);
		for (int i = onecolnum; i < twocolnum; i++) {
			if (x[i].getValue())
				bpvis[i - onecolnum] = true;

		}
		RecordResult(p_graph, apvis, bpvis);
		return true;
	} catch (const LSException& e) {
		cout << "LSException occurred:" << e.getMessage() << endl;
	}

	return false;
}
